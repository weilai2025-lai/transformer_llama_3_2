# 📝 學習備忘錄：Tokenizer 與 C 指標（階段性整理）

**本筆記目標：**  
在沒有 C 語言背景的前提下，理解 tokenizer 中 `char *`、`char **` 的真實用途與記憶體語意

---

## 1️⃣ 環境與執行（實作背景）

- **作業系統：** macOS（M4 Pro）  
  → 已確認具備完整 C / gcc 編譯環境
- **相依函式庫：**
  - 安裝 `pcre` 函式庫，用於 tokenizer 的字串切割（正則表示式）
- **編譯方式：**
  - 使用 `gcc`
  - 手動連結 Homebrew 路徑下的函式庫
  - 成功產生 `run` 可執行檔
- **記憶體修正（重要）：**
  - Llama 3.2 3B 預設 `seq_len = 128K`
  - 導致實體記憶體申請失敗（`malloc` 失敗）
  - 在 `build_transformer` 中強制限制 `seq_len = 512`
  - 才能順利在本機執行

> 📌 **關鍵理解：**  
> `seq_len` 不只是模型參數，而是直接影響 runtime 記憶體配置大小

---

## 2️⃣ 模型結構基礎概念（與 tokenizer 有關）

| 參數 | 說明 |
|------|------|
| `vocab_size` | 字典總容量。Llama 3.2：128,256 個 token |
| `dim` | token embedding 向量維度。3B 模型為 3072 |
| `seq_len` | 模型一次推論可處理的最大 token 長度，同時也是推論 buffer 的大小上限 |

> 📌 **直覺記憶：**  
> - `vocab_size` 決定「有多少個詞」  
> - `seq_len` 決定「一次能看多長的句子」

---

## 3️⃣ Tokenizer 的核心資料結構

### 3.1 vocab：ID → 字串

```c
char **vocab;
```

**用途：**
- 依照 token ID 取得對應的文字
- 用於「ID → 文字」的反查（decode）

**概念上是什麼？**
- 一張表
- 每一格存一個 `char *`
- 每個 `char *` 指向一個完整 token 字串的「開頭位址」

**例子（概念）：**
```
vocab[0] -> "the"
vocab[1] -> "love"
vocab[2] -> "fpga"
```

> ⚠️ **重點：**  
> `vocab[i]` 不是字串本身，而是「指向字串起點的位址（`char *`）」

---

### 3.2 sorted_vocab：文字 → ID

```c
TokenIndex *sorted_vocab;
```

其中：

```c
typedef struct {
    char *str;
    int id;
} TokenIndex;
```

**用途：**
- 依照文字查找 token ID
- 用於 tokenizer 的 encode（文字 → token）

**為什麼不用 `char **`？**  
因為這裡需要「字串 + ID」綁在一起做搜尋與排序

**每一個元素長這樣：**
```
TokenIndex:
  ├─ str -> 指向 token 字串
  └─ id  -> 對應的 token ID
```

> 📌 `sorted_vocab` 是一整排 struct 陣列，通常依字母順序排序，加速查找。

---

### 3.3 vocab_scores

```c
float *vocab_scores;
```

**用途：**
- 每個 token 對應一個分數（權重）
- 在 BPE / Unigram 等分詞策略中，用來決定「合併優先順序」

```
vocab[i]        -> 第 i 個 token 字串
vocab_scores[i] -> 第 i 個 token 的分數
```

---

## 4️⃣ C 語言指標的直覺理解（重點整理）

### 4.1 `char *`（一級指標）

> 一張「寫著置物櫃編號的紙條」

假設字串 `"fpga"` 在記憶體中：

```
位址 100: 'f'
位址 101: 'p'
位址 102: 'g'
位址 103: 'a'
位址 104: '\0'
```

```c
char *str = "fpga";
```

- `str` 存的是 `100`
- `*str` 只會取出一個字元 `'f'`
- C 不知道字串長度，只能一路讀，直到遇到 `'\0'`

> 📌 **關鍵定錨句：**  
> C 字串只有「起點位址」，沒有長度

---

### 4.2 `char **`（二級指標）

> 一個「裝滿紙條的盒子」

字典裡有很多單字，各自存在記憶體的不同位置：
```
"the"  : 't' 在位址 100, 'h' 在 101, 'e' 在 102, '\0' 在 103
"love" : 'l' 在位址 500, 'o' 在 501, 'v' 在 502, 'e' 在 503, '\0' 在 504
"fpga" : 'f' 在位址 900, 'p' 在 901, 'g' 在 902, 'a' 在 903, '\0' 在 904
```

```c
char **vocab;
```

概念上：
```
vocab[0] -> 100（指向 't' 的位址，即 "the" 的起點）
vocab[1] -> 500（指向 'l' 的位址，即 "love" 的起點）
vocab[2] -> 900（指向 'f' 的位址，即 "fpga" 的起點）
```

> ⚠️ **注意：**  
> `vocab[i]` 返回的是 `char *`（指向**第一個字元**的位址），  
> 而不是「整個字串」。C 語言會從這個位址開始讀，直到遇到 `'\0'` 才知道字串結束。

> 📌 **為什麼 tokenizer 需要 `char **`？**
> - 每個 token 長度不同
> - 若用固定長度陣列會浪費大量記憶體
> - 用 `char **`：
>   - 只存「地址表」
>   - 字串本體可以分散在記憶體任何地方

---

## 5️⃣ 為什麼 `char **` 也「無法一次取出整個字串」？

即使是：
```c
vocab[1]
```

- 拿到的仍然只是**字串起點位址（`char *`）**
- 並不存在「整個字串」這種型別

真正能「看到完整字串」是因為：

```c
printf("%s", vocab[1]);
```

👉 `printf` 會：
1. 從該位址開始
2. 一個一個讀 `char`
3. 直到遇到 `'\0'` 才停止

> 📌 **核心結論（非常重要）：**  
> 在 C 裡，沒有「一次性取出整個字串」這件事，只有「從位址開始，讀到 `'\0'` 為止」。

---

## ✅ 最終總結（一句話版本）

| 指標類型 | 意義 |
|----------|------|
| `char *` | 指向一個字串的起點 |
| `char **` | 指向「很多個字串起點」的表 |

- C 字串沒有長度
- `'\0'` 是唯一的停止條件

**Tokenizer 的所有設計，都是在這個前提下成立的。**

---

## 6️⃣ Llama 3.2 分詞流程（兩段式設計）

根據 `run.c` 代碼，Llama 3.2 並非一開始就切碎，而是有優化路徑：

1. **Regex Split（預切割）：** 先用正規表達式把句子切成「塊」（如 `"apple"`）
2. **Direct Lookup（直接查找）：** 拿這個「塊」去 `sorted_vocab` 查
   - ✅ 查到了：直接拿 ID 結案，不跑 BPE
   - ❌ 查不到：進入 BPE 流程
3. **BPE 流程：**
   - (a) 將該塊拆成最小單位（Bytes）
   - (b) 查詢 `vocab_scores` 找出最高分的組合進行合併
   - (c) 重複直到無法再合併

---

## 7️⃣ C 語言指標對照表（位址 vs 值）

| 語法 | 類型 | 實際意義 | 硬體(RTL)聯想 |
|------|------|----------|---------------|
| `vocab` | `char **` | 指向「地址清單」的起點 | 記憶體中「地址表」的 Base Address |
| `vocab[i]` | `char *` | 第 i 個單字的「起始位址」 | 發起一次 DMA 讀取的起始位置 |
| `*vocab[i]` | `char` | 第 i 個單字的「第一個字元」 | 讀回來的資料流中的第一個 Byte |
| `vocab[i][j]` | `char` | 第 i 個單字的第 j 個字元 | 讀回來的資料流中的第 j 個 Byte |
| `&vocab[i]` | `char **` | 指向「第 i 個地址」的位址 | 指向存放地址的地址（指標運算用） |

---

> 📍 **下一階段目標：**  
> 深入閱讀 `encode` 函式內的 BPE 迴圈，理解其如何動態更新緩衝區並進行分數比對。
